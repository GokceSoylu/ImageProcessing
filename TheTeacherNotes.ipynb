{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opnecvBasic.pt\n",
    "\n",
    "#Firstly, requirements list, import library\n",
    "import cv2\n",
    "\n",
    "print(cv2.__version__)\n",
    "\n",
    "#Import Image File\n",
    "img = cv2.imread('image.jpg')\n",
    "\n",
    "#Show Image\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "#Problem Solution about image showing\n",
    "if(cv2.waitKey(0)):\n",
    "    #Image save\n",
    "    cv2.imwrite('imagesave.jpg',img)\n",
    "    \n",
    "    #Destroy all opened window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openColer.py\n",
    "import cv2\n",
    "\n",
    "#flags 1, 0 or -1 (1 unchanged, 0 gray, -1 alpha channel)\n",
    "img_rgb = cv2.imread('image.jpg')\n",
    "img_rgb_gry = cv2.imread('image.jpg', 0)\n",
    "\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "#Image Shape Information, channel 1 blue, channel 2 green, channel 3 red\n",
    "h, w, c = img_rgb.shape\n",
    "\n",
    "#Image Show and Resize Window\n",
    "cv2.namedWindow('Original Image', 2)\n",
    "cv2.resizeWindow('Original Image', img_rgb.shape[1] + 2 * img_rgb.shape[1], img_rgb.shape[0] + 2 * img_rgb.shape[0])\n",
    "\n",
    "cv2.namedWindow('Gray Image', 2)\n",
    "cv2.resizeWindow('Gray Image', img_rgb.shape[1] + 2 * img_rgb.shape[1], img_rgb.shape[0] + 2 * img_rgb.shape[0])\n",
    "\n",
    "cv2.namedWindow('Gray Image with First', 2)\n",
    "cv2.resizeWindow('Gray Image with First', img_rgb.shape[1] + 2 * img_rgb.shape[1], img_rgb.shape[0] + 2 * img_rgb.shape[0])\n",
    "\n",
    "cv2.imshow('Original Image', img_rgb)\n",
    "\n",
    "b, g, r = cv2.split(img_rgb)\n",
    "b_1 = img_rgb[:,:,0]\n",
    "g_1 = img_rgb[:,:,1]\n",
    "r_1 = img_rgb[:,:,2]\n",
    "\n",
    "cv2.imshow('Blue', b)\n",
    "cv2.imshow('Green', g)\n",
    "cv2.imshow('Red', r)\n",
    "\n",
    "cv2.imshow('Gray Image', img_gray)\n",
    "cv2.imshow('Gray Image with First', img_rgb_gry)\n",
    "\n",
    "if(cv2.waitKey(0)):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvColorWithColorTrackBarpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def onChange(x):\n",
    "    pass\n",
    "\n",
    "#Color Window Create And Resize\n",
    "cv2.namedWindow('RGB Color',2)\n",
    "cv2.resizeWindow('RGB Color', 600, 600)\n",
    "\n",
    "#Create Trackbar\n",
    "cv2.createTrackbar('R', 'RGB Color', 0, 255, onChange)\n",
    "cv2.createTrackbar('G', 'RGB Color', 0, 255, onChange)\n",
    "cv2.createTrackbar('B', 'RGB Color', 0, 255, onChange)\n",
    "\n",
    "while(1):\n",
    "    #Get Trackbar Color Value\n",
    "    R = cv2.getTrackbarPos('R', 'RGB Color')\n",
    "    G = cv2.getTrackbarPos('G', 'RGB Color')\n",
    "    B = cv2.getTrackbarPos('B', 'RGB Color')\n",
    "    \n",
    "    print(R,G,B)\n",
    "    \n",
    "    #Create Image with Zeros\n",
    "    img = np.zeros((300, 300, 3), np.uint8)\n",
    "    \n",
    "    img[:,:,0] = B\n",
    "    img[:,:,1] = G\n",
    "    img[:,:,2] = R\n",
    "    \n",
    "    cv2.imshow('RGB Color', img)\n",
    "    \n",
    "    if(cv2.waitKey(1) == 27):\n",
    "        cv2.destroyAllWindows()\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvVonvolition.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as py\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "image = cv2.imread('lena.jpg', 0)\n",
    "row, col = image.shape\n",
    "\n",
    "#kernel = np.ones((5,5),np.float32)/25\n",
    "kernel = np.array([\n",
    "    [ 0 ,-1, 0],\n",
    "    [-1,  5,-1],\n",
    "    [ 0 ,-1, 0]])\n",
    "out = np.zeros((row, col))\n",
    "\n",
    "kCols, kRows = kernel.shape\n",
    "\n",
    "kCenterX = int(kCols / 2)\n",
    "kCenterY = int(kRows / 2)\n",
    "\n",
    "for i in range(0, row):\n",
    "    for j in range(0, col):\n",
    "        for m in range(0, kRows):\n",
    "            mm = kRows - 1 - m\n",
    "            for n in range(0, kCols):\n",
    "                nn = kCols - 1 - n\n",
    "                \n",
    "                ii = i + (kCenterY - mm)\n",
    "                jj = j + (kCenterX - nn)\n",
    "                \n",
    "                if (ii >= 0 and ii < row) and (jj >=0 and jj < col):\n",
    "                    out[i, j] = out[i, j] + image[ii, jj] * kernel[mm, nn]\n",
    "                    \n",
    "img_rst = cv2.filter2D(image,-1,kernel, cv2.BORDER_REFLECT)\n",
    "out_2 = np.around(out).astype(np.uint8)\n",
    "\n",
    "def convolution2d(image, kernel, pad):\n",
    "    m, n = kernel.shape\n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_DEFAULT, value=0)\n",
    "    y, x = image.shape\n",
    "    y_out = y - m + 1\n",
    "    x_out  = x - n + 1\n",
    "    new_image = np.zeros((y_out, x_out))\n",
    "    for i in range(y_out):\n",
    "        for j in range(x_out):\n",
    "            new_image[i][j] = np.sum(image[i:i+m, j:j+n]*kernel)\n",
    "    return new_image\n",
    "\n",
    "pad = int(kCols / 2)\n",
    "conv = convolution2d(image, kernel, pad)\n",
    "blur = cv2.blur(image,(5,5))\n",
    "\n",
    "#rescale the output image to be in the range [0, 255]\n",
    "output = rescale_intensity(conv, in_range=(0, 255))\n",
    "output = (output * 255).astype(\"uint8\")\n",
    "\n",
    "#Plot Image\n",
    "py.subplot(321), py.imshow(image, cmap='gray', interpolation='nearest'), py.title('Original Image')\n",
    "py.subplot(322), py.imshow(output, cmap='gray', interpolation='nearest'), py.title('Manual Filtering with Convolution2d Function')\n",
    "py.subplot(323), py.imshow(blur, cmap='gray', interpolation='nearest'), py.title('Blur Filter')\n",
    "py.subplot(324), py.imshow(img_rst, cmap='gray', interpolation='nearest'), py.title('Filter 2D Function')\n",
    "py.subplot(325), py.imshow(out_2, cmap='gray', interpolation='nearest'), py.title('Manual Filtering')\n",
    "\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvHistogramEqualization.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Read Image\n",
    "img = cv2.imread(\"image.jpg\", 0)\n",
    "hist = cv2.calcHist(img, [2], None, [256], [0,256])\n",
    "\n",
    "#Plot Histogram For Each RGB Channels\n",
    "# for i in range(0,2):\n",
    "#     hist = cv2.calcHist(img, [i], None, [256], [0,256])\n",
    "#     plt.plot(hist)\n",
    "#     plt.xlim([0,256])\n",
    "\n",
    "# plt.hist(img.ravel(), 256, [0,256])\n",
    "# plt.show()\n",
    "\n",
    "#Self Function for Calculating Histogram\n",
    "hist_self = np.zeros([256])\n",
    "\n",
    "for x in range(img.shape[0]):\n",
    "    for y in range(img.shape[1]):\n",
    "        px = img[x,y]\n",
    "        hist_self[px] += 1\n",
    "        \n",
    "\n",
    "#Histogram Equalization\n",
    "hist_eq = cv2.equalizeHist(img)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Histogram Equalizatied Image', hist_eq)\n",
    "\n",
    "\n",
    "plt.hist(hist_eq.ravel(), 256, [0,256])\n",
    "plt.show()\n",
    "\n",
    "if(cv2.waitKey(0) == 27):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvMorphologicalFeatyre.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as py\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "import imutils\n",
    "from scipy.spatial import distance as dist\n",
    "import pandas as pd\n",
    "\n",
    "#Reading image file\n",
    "#imread(image path, color = 1, unchanged (with alpha channel) = -1, gray = 0)\n",
    "RGB = cv2.imread('karakter.jpg',1)\n",
    "# cv2.imshow('Orgiinal Image',RGB)\n",
    "RGB_copy = RGB.copy()\n",
    "\n",
    "#Image transform to Gray Image\n",
    "#cvtColor using for transform different domain (color RGB, HSV,CMYK, YUV, GRAY, etc.)\n",
    "I_gray = cv2.cvtColor(RGB, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow('Gray Image', I_gray)\n",
    "\n",
    "#Image convert to binaty image using THRESH_OTSU (it is optimization algorithm for finding best threshold value)\n",
    "ret1, I_thresh = cv2.threshold(I_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "#cv2.imshow('Binary Image with threshold', I_thresh)\n",
    "\n",
    "# if cv2.waitKey(0) & 0xff == 27 | ord('c'):\n",
    "#    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def bwareaopen(image):\n",
    "    #find all your connected components (white blobs in your image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    #connectedComponentswithStats yields every seperated component with information on each of them, such as size\n",
    "    #the following part is just taking out the background which is also considered a component, but most of the time we don't want that.\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "    \n",
    "    # minimum size of particles we want to keep (number of pixels)\n",
    "    #here, it's a fixed value, but you can set it as you want, eg the mean of the sizes or whatever\n",
    "    min_size = 10  \n",
    "    \n",
    "    #your answer image\n",
    "    img2 = np.zeros((output.shape))\n",
    "    #for every component in the image, you keep it only if it's above min_size\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= min_size:\n",
    "            img2[output == i + 1] = 255\n",
    "            \n",
    "    return img2\n",
    "\n",
    "I_bw = bwareaopen(I_thresh)\n",
    "I_bn = I_bw.astype(np.uint8)\n",
    "\n",
    "I_contours,_ = cv2.findContours(I_bn, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "I_drawcountours = cv2.drawContours(RGB_copy, I_contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "strel = np.ones((2,2),np.uint8)\n",
    "I_dilation = cv2.dilate(I_bn, strel, iterations = 1)\n",
    "I_fill = I_dilation.copy()\n",
    "\n",
    "# Mask used to flood filling.\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "h, w = I_fill.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "# Floodfill from point (0, 0)\n",
    "I_fill = I_fill.astype(np.uint8)\n",
    "cv2.floodFill(I_fill, mask, (0,0), 255)\n",
    "\n",
    "# Invert floodfilled image\n",
    "I_fill_inv = cv2.bitwise_not(I_fill)\n",
    "\n",
    "# Combine the two images to get the foreground.\n",
    "I_out = I_dilation | I_fill_inv\n",
    "\n",
    "cnts = cv2.findContours(I_out, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "# sort the contours from left-to-right and initialize the\n",
    "# 'pixels per metric' calibration variable\n",
    "(cnts, _) = contours.sort_contours(cnts)\n",
    "pixelsPerMetric = None\n",
    "\n",
    "area = list()\n",
    "per = list()\n",
    "\n",
    "\n",
    "orig = RGB.copy()\n",
    "\n",
    "def midpoint(ptA, ptB):\n",
    "\treturn ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "count = 0\n",
    "ekcount = 0\n",
    "cl = 1\n",
    "classes = []\n",
    "\n",
    "# loop over the contours individually\n",
    "for c in cnts:\n",
    "  # if the contour is not sufficiently large, ignore it\n",
    "  if cv2.contourArea(c) < 10:\n",
    "    continue\n",
    "  # compute the rotated bounding box of the contour\n",
    "  box = cv2.minAreaRect(c)\n",
    "  box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "  box = np.array(box, dtype=\"int\")\n",
    "  \n",
    "  area.append(cv2.contourArea(c))\n",
    "  per.append(cv2.arcLength(c,True))\n",
    "  \n",
    "  x,y,w,h = cv2.boundingRect(c)\n",
    "  aspect_ratio = float(w)/h\n",
    "  \n",
    "  extent = float(cv2.contourArea(c))/(w*h)\n",
    "  \n",
    "  hull = cv2.convexHull(c)\n",
    "  solidity = float(cv2.contourArea(c))/cv2.contourArea(hull)\n",
    "\n",
    "  equi_dia = np.sqrt(4*cv2.contourArea(c)/np.pi)\n",
    "  \n",
    "  leftmost = tuple(c[c[:,:,0].argmin()][0])\n",
    "  rightmost = tuple(c[c[:,:,0].argmax()][0])\n",
    "  topmost = tuple(c[c[:,:,1].argmin()][0])\n",
    "  bottommost = tuple(c[c[:,:,1].argmax()][0])\n",
    "  \n",
    "  \n",
    "  if count > 4:\n",
    "      count = 0\n",
    "      cl = cl + 1\n",
    "\n",
    "  if cl == 10:\n",
    "      cl = 0\n",
    "\n",
    "\n",
    "  classes.append(cl)   \n",
    "  count = count + 1\n",
    "  ekcount = ekcount + 1\n",
    "  \n",
    "  df = pd.DataFrame({\n",
    "        'area': area,\n",
    "        'perimeter': per,\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'width': w,\n",
    "        'height': h,\n",
    "        'aspect_ratio': aspect_ratio,\n",
    "        'extent': extent,\n",
    "        'solidity': solidity,\n",
    "        'equivalent_diameter': equi_dia,\n",
    "        'leftx': leftmost[0],\n",
    "        'lefty': leftmost[1],\n",
    "        'rightx': rightmost[0],\n",
    "        'righty': rightmost[1],\n",
    "        'topx': topmost[0],\n",
    "        'topy': topmost[1],\n",
    "        'bottomx': bottommost[0],\n",
    "        'bottomy': bottommost[1]})\n",
    "\n",
    "\n",
    "  # order the points in the contour such that they appear\n",
    "  # in top-left, top-right, bottom-right, and bottom-left\n",
    "  # order, then draw the outline of the rotated bounding\n",
    "  # box\n",
    "  box = perspective.order_points(box)\n",
    "  cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "  # loop over the original points and draw them\n",
    "  for (x, y) in box:\n",
    "    cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "    (tl,tr,br,bl) = box\n",
    "    \n",
    "    \n",
    "    (tltrX, tltrY) = midpoint(tl, tr)\n",
    "    (blbrX, blbrY) = midpoint(bl, br)\n",
    "      # compute the midpoint between the top-left and top-right points,\n",
    "      # followed by the midpoint between the top-righ and bottom-right\n",
    "    (tlblX, tlblY) = midpoint(tl, bl)\n",
    "    (trbrX, trbrY) = midpoint(tr, br)\n",
    "      # draw the midpoints on the image\n",
    "    cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n",
    "    cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n",
    "    cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n",
    "    cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n",
    "      # draw lines between the midpoints\n",
    "    cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),(255, 0, 255), 1)\n",
    "    cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),(255, 0, 255), 1)\n",
    "    # compute the Euclidean distance between the midpoints\n",
    "    dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "    dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "\t# if the pixels per metric has not been initialized, then\n",
    "\t# compute it as the ratio of pixels to supplied metric\n",
    "\t# (in this case, inches)\n",
    "    if pixelsPerMetric is None:\n",
    "        pixelsPerMetric = dB / 0.955\n",
    "    # compute the size of the object\n",
    "    dimA = dA / pixelsPerMetric\n",
    "    dimB = dB / pixelsPerMetric\n",
    "    cv2.putText(orig, \"{:.1f}in\".format(dimA),\n",
    "\t\t(int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t0.15, (0, 255, 255), 1)\n",
    "    cv2.putText(orig, \"{:.1f}in\".format(dimB),\n",
    "\t\t(int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t0.15, (0, 255, 255), 1)\n",
    "\n",
    "\n",
    "#Plot Image\n",
    "py.subplot(331), py.imshow(RGB, cmap='gray', interpolation='nearest'), py.title('Original Image')\n",
    "py.subplot(332), py.imshow(I_gray, cmap='gray', interpolation='nearest'), py.title('Gray Image')\n",
    "py.subplot(333), py.imshow(I_thresh, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "py.subplot(334), py.imshow(I_bw, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "py.subplot(335), py.imshow(I_drawcountours, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "py.subplot(336), py.imshow(I_dilation, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "py.subplot(337), py.imshow(I_out, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "py.subplot(338), \n",
    "#py.imshow(orig, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "#py.subplot(338), py.imshow(I_out, cmap='gray', interpolation='nearest'), py.title('Binary Image using Threshold')\n",
    "\n",
    "py.show()\n",
    "\n",
    "df2 = pd.DataFrame(classes, columns=['class'])\n",
    "veri = pd.concat([df2,df], axis = 1 )\n",
    "\n",
    "\n",
    "        #per = np.array(np.vstack(contours).squeeze())\n",
    "        # center_array = np.full((per.shape[0], per.shape[1]), center, dtype=int)\n",
    "        \n",
    "        # ma = per - center_array\n",
    "        # ma2 = np.sqrt(np.square(ma[:,0])/h + np.square(ma[:,1])/w)\n",
    "        \n",
    "        # major = int(np.amax(ma2))\n",
    "        # minor = int(np.amin(ma2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opemcvTreshold\n",
    "#Thresholding\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Read Image\n",
    "img = cv2.imread('image.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "#Image Window Resize\n",
    "cv2.namedWindow('Thresholded Image', 2)\n",
    "cv2.resizeWindow('Thresholded Image', h + h *2 , w + w*2)\n",
    "\n",
    "cv2.namedWindow('Original Image', 2)\n",
    "cv2.resizeWindow('Original Image', h + h *2 , w + w*2)\n",
    "\n",
    "cv2.namedWindow('Horizantally Multiple Image', 2)\n",
    "cv2.resizeWindow('Horizantally Multiple Image', h + h *4 , w + w*2)\n",
    "\n",
    "cv2.namedWindow('Vertically Multiple Image', 2)\n",
    "cv2.resizeWindow('Vertically Multiple Image', h + h *2 , w + w*4)\n",
    "\n",
    "#Convert Color Image to Gray Image\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = 0\n",
    "maxval = 255\n",
    "r, img_thresh = cv2.threshold(img_gray, thresh, maxval, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "#Show image with OpenCV\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Thresholded Image', img_thresh)\n",
    "\n",
    "img_mul_hor = np.concatenate((img_gray, img_thresh), axis = 1)\n",
    "cv2.imshow('Horizantally Multiple Image', img_mul_hor)\n",
    "\n",
    "img_mul_ver = np.concatenate((img_gray, img_thresh), axis = 0)\n",
    "cv2.imshow('Vertically Multiple Image', img_mul_ver)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img, plt.cm.gray)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Thresholded Image\")\n",
    "plt.imshow(img_thresh, plt.cm.gray)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig2 = plt.figure(2)\n",
    "image_title = [\"Original\", \"Gray\", \"Thresh\"]\n",
    "image_list = [img, img_gray, img_thresh]\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    plt.subplot(1,3,i + 1)\n",
    "    plt.title(image_title[i])\n",
    "    plt.imshow(image_list[i], plt.cm.gray)\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "if(cv2.waitKey(0) == 27):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvTresholdWithTrackBar.py\n",
    "#Thresholding with Trackbar\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def onChange(x):\n",
    "    pass\n",
    "\n",
    "#Read Image\n",
    "img = cv2.imread('image.jpg')\n",
    "\n",
    "#Image Clone\n",
    "img_copy = img.copy()\n",
    "\n",
    "\n",
    "h, w, c = img.shape\n",
    "maxval = 255\n",
    "\n",
    "#Image Window Resize\n",
    "cv2.namedWindow('Thresholded Image', 2)\n",
    "cv2.resizeWindow('Thresholded Image', h + h *2 , w + w*2)\n",
    "\n",
    "#Convert Color Image to Gray Image\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#img_gray = cv2.imread('image.jpg', 0)\n",
    "\n",
    "#Create Trackbar\n",
    "cv2.createTrackbar('Thresh Min', 'Thresholded Image', 0, 255, onChange)\n",
    "cv2.createTrackbar('Thresh Max', 'Thresholded Image', 0, 255, onChange)\n",
    "\n",
    "while True:\n",
    "    threshmin = cv2.getTrackbarPos('Thresh Min', 'Thresholded Image')\n",
    "    threshmax = cv2.getTrackbarPos('Thresh Max', 'Thresholded Image')\n",
    "    r, img_thresh = cv2.threshold(img_gray, threshmin, threshmax, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    #Show image with OpenCV\n",
    "    cv2.imshow('Thresholded Image', img_thresh)\n",
    "    \n",
    "    \n",
    "    if(cv2.waitKey(1) == 27):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " opencvVideProccessing.py\n",
    " import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "deger = 3000\n",
    "adet = 0\n",
    "kontrol = 0\n",
    "degerlistesi = []\n",
    "time.sleep(15)\n",
    "\n",
    "renk = \"\"\n",
    "\n",
    "while(1):\n",
    "\n",
    "    frm,imaj = cap.read()\n",
    "\n",
    "    cv2.imwrite('img.png', imaj)\n",
    "\n",
    "    img = cv2.imread('img.png')\n",
    "    #cv2.imshow('imaj',img)\n",
    "\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    img_yuv[:,0,:] = cv2.equalizeHist(img_yuv[:,0,:])\n",
    "    img_yuv[0,:,:] = cv2.equalizeHist(img_yuv[0,:,:])\n",
    "\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    hsv = cv2.cvtColor(img_output, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    red_lower = np.array([136,87,111], np.uint8)\n",
    "    red_upper = np.array([180,255,255], np.uint8)\n",
    "\n",
    "    blue_lower = np.array([94,80,2], np.uint8)\n",
    "    blue_upper = np.array([120,255,255], np.uint8)\n",
    "\n",
    "    yellow_lower = np.array([22,52,72], np.uint8)\n",
    "    yellow_upper = np.array([102,255,255], np.uint8)\n",
    "\n",
    "    red = cv2.inRange(hsv, red_lower, red_upper)\n",
    "    blue = cv2.inRange(hsv, blue_lower, blue_upper)\n",
    "    yellow = cv2.inRange(hsv, yellow_lower, yellow_upper)\n",
    "\n",
    "    kernel = np.ones((5,5), \"uint8\")\n",
    "\n",
    "    red = cv2.dilate(red,kernel)\n",
    "    res = cv2.bitwise_and(img, img, mask = red)\n",
    "\n",
    "    #cv2.imshow('red',red)\n",
    "    #cv2.imshow('red',res)\n",
    "\n",
    "    blue= cv2.dilate(blue,kernel)\n",
    "    res1 = cv2.bitwise_and(img, img, mask = blue)\n",
    "\n",
    "    #cv2.imshow('blue',blue)\n",
    "    #cv2.imshow('blue',res1)\n",
    "\n",
    "    yellow= cv2.dilate(yellow,kernel)\n",
    "    res2 = cv2.bitwise_and(img, img, mask = yellow)\n",
    "\n",
    "    #cv2.imshow('yellow',yellow)\n",
    "    #cv2.imshow('yellow',res2)\n",
    "\n",
    "    rgy = red + blue + yellow\n",
    "\n",
    "    imaj = res + res1 + res2\n",
    "    #cv2.imshow('imajim', imaj)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(rgy, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contours = contours[0] if imutils.is_cv2() else contours[1]\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > deger):\n",
    "                M = cv2.moments(contour)\n",
    "                if int(M['m00']) > 0:\n",
    "                    cX = int(M['m10'] / M['m00'])\n",
    "                    cY = int(M['m01'] / M['m00'])\n",
    "\n",
    "                    b,g,r = cv2.split(hsv)\n",
    "\n",
    "                    b_mean = b[cY][cX]\n",
    "                    g_mean = g[cY][cX]\n",
    "                    r_mean = r[cY][cX]\n",
    "\n",
    "                    if b_mean >= 136 and b_mean <= 180 and g_mean >= 87 and g_mean <= 255 and r_mean >=111 and r_mean <= 255:\n",
    "                        cv2.putText(img, \"RED\", (cX -20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                        degerlistesi.append(\"RED\")\n",
    "                        renk += renk + str(0)\n",
    "                    elif b_mean >= 91 and b_mean <= 130 and g_mean >= 80 and g_mean <= 255 and r_mean >= 125 and r_mean <= 255:\n",
    "                        cv2.putText(img, \"BLUE\", (cX -20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                        degerlistesi.append(\"BLUE\")\n",
    "                        renk += renk + str(\"1\")\n",
    "                    else:\n",
    "                        cv2.putText(img, \"YELLOW\", (cX -20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
    "                        degerlistesi.append(\"YELLOW\")\n",
    "                        renk += renk + str(\"2\")\n",
    "\n",
    "    #if(len(renk) > 16):\n",
    "        #renk = renk[0:15]\n",
    "    #else:\n",
    "        #for index in range(0, len(renk)):\n",
    "            #renk += renk + str(0)\n",
    "    #print(renk)\n",
    "\n",
    "    #print(degerlistesi)\n",
    "    cv2.imshow('Video',img)\n",
    "    #time.sleep(10)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # opencvWaqterShedSkLearn.py\n",
    " import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import segmentation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img = np.zeros((256, 256),dtype=\"uint8\")\n",
    "cv2.circle(img, (70,70), 50, (255,255,255), (-1))\n",
    "cv2.circle(img, (140,140), 70, (255,255,255), (-1))\n",
    "\n",
    "dist_transform = cv2.distanceTransform(img, cv2.DIST_L2,3)\n",
    "\n",
    "local_max_location = peak_local_max(dist_transform, min_distance=2, indices=True)\n",
    "local_max_boolean = peak_local_max(dist_transform, min_distance=2, indices=False)\n",
    "\n",
    "markers, _ = ndi.label(local_max_boolean)\n",
    "\n",
    "segmented = segmentation.watershed(255-dist_transform, markers, mask=img)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(img, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Input image')\n",
    "ax[1].imshow(-dist_transform, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Distance transform')\n",
    "ax[2].imshow(segmented, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvWaterShed.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('water_coins.jpg')\n",
    "img_original = img.copy()\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(img_original, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Input image')\n",
    "ax[1].imshow(dist_transform, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Distance transform')\n",
    "ax[2].imshow(img, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
